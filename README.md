# toynet
Toys for Talki

Project manager with Firebase account henrik@thepia.com / henrik%thepia.com@gtempaccount.com

images: Source images organised by primary label as the name of directories within. Each file is also prefixed with the label.
dataset: Extracted images based on bounding boxes and label.

annotations: The annotated dataset split in training and evaluation records. 

This is to be implemented as [YoloV3 Implemented in TensorFlow 2.0](https://github.com/zzh8829/yolov3-tf2). It provides a clean implementation of YoloV3 in TensorFlow 2.0 using all the best practices.

Follow the plain for YoloV3 at [YOLO](./YOLO3.md)


## Google Cloud

https://console.cloud.google.com/vision/datasets?authuser=0&project=ignore-the-gap&folder=&organizationId=

[Cloud Storage Blobs/Objects](https://googleapis.dev/python/storage/latest/blobs.html#google.cloud.storage.blob.Blob)

[AutoML API for Python](https://googleapis.dev/python/automl/latest/index.html)
[gcloud Install](https://cloud.google.com/sdk/gcloud/)
[Cloud API Auth](https://googleapis.dev/python/google-api-core/latest/auth.html)

If `gcloud init` or `gcloud login` doesn't work use `gcloud auth login --no-launch-browser`.

Download credentials file and set reference in `.bash_profile`.


> POST https://automl.googleapis.com/v1/projects/ignore-the-gap/locations/europe-west1/models/IOD2523258239466864640:export


> curl -X POST \
-H "Authorization: Bearer "$(gcloud auth print-access-token) \
-H "Content-Type: application/json; charset=utf-8" \
-d @tools/export-request.json \
https://automl.googleapis.com/v1/projects/402831859832/locations/europe-west1/models/IOD2523258239466864640:export


Exporting 

Save TF Lite to bucket toynet-us(in us-central-1)

Then download locally

> gsutil cp -r gs://toynet-us .



## Labelling

For local labelling use [LabelImg](https://github.com/tzutalin/labelImg).


## Using Miniconda

Download and install the package in web browser (see darknet)

> conda create -n toynet python=3.8
> conda activate toynet

To change python version
> sudo conda install python=3.8

Environment Location = ~/opt/miniconda3/envs/toynet


## Steps before Using

Install by
> brew install rename
> pip3 install -r ./requirements.txt

Save images to the correct folder in `images`. Run the `autorotate.sh` script to ensure that any rotation information in the EXIF data of the JPEGs are applied so the base picture has the right rotation. Make sure that jpegtrans and nconvert are installed as per [SuperUser](https://superuser.com/questions/670818/how-to-automatically-rotate-images-based-on-exif-data) and [XNView](https://www.xnview.com/en/nconvert/#downloads)

Take new pictures with the dedicated iPad which produces 1280x960 JPEGs at around 300-400Kb.
Place the images in the correct label directory.
Run `link-all-images.sh` to rename the images from 'IMG_' to the correct label prefix and link them in the images folder so VoTT will see them.
Use Microsoft [VoTT](https://github.com/microsoft/VoTT/releases) to label objects in the images.

Will all images properly labelled the dataset images are generated by running `make-dataset.py`.

TODO: Some images contain more than one label. The script must be improved to output unique files per label per picture, so the training is done correctly.

?? Should the box contain all of the object, or a balanced box with equal part cut off and background included.

?? How to make Quality Image Dataset/Net

TODO: expand with rotated versions. resize to specific size.
TODO: video testing of reduced size KModel.

## Darknet for Object Recognition

Darknet seems to be the proven way that will work on the Edge ML chipsets.

[Darknet by Alexey](https://github.com/AlexeyAB/darknet)


## Google Open Images

> oidv6 downloader en --dataset ../dataset --type_data all --classes "Teddy Bear" --limit 20

images/downloader.py

Names:

Toy
Doll
Balloon
Teddy bear

Office supplies - Scissors
Helmet - Bicycle Helmet
Kitchen utensil - Knife
Weapon - Knife

Telephone - Mobile phone
Telephone - Corded phone
Building - Remote control

Person:
Man
Woman
Boy
Girl
Body part
Human face
Human hand
Human eye


## Tensorflow Training

Tensorflow models git repository must be checked out at `/Volumes/Project/models`. Symlinks in this repository rely on the location.
Use the script `train-dataset.py` to create TFRecords from the dataset directory and train using transfer learning.
At the end of the training images will be shown for the result of the evaluation set.


The Tensorflow retrain guide is focused on classification of the whole image.
https://www.tensorflow.org/hub/tutorials/image_retraining


How to train your own Object Detector with TensorFlowâ€™s Object Detector API
https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9

Official local training guide
- Naming could be better
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md?source=post_page---------------------------

[Towards Deep Learning using TensorFlow Lite on RISC-V](https://edge.seas.harvard.edu/files/edge/files/carrv_workshop_submission_2019_camera_ready.pdf)

[Can Apple's M1 help you train models faster & cheaper](https://wandb.ai/vanpelt/m1-benchmark/reports/Can-Apple-s-M1-help-you-train-models-faster-cheaper-than-NVIDIA-s-V100---VmlldzozNTkyMzg)



## Freezing after Training

tools link to: /usr/local/lib/python3.7/site-packages/tensorflow/python/tools

python tools/freeze_graph.py \
--input_graph=model/saved_model.pb \
--input_checkpoint=./model/checkpoint \
--output_graph=./model/frozen_network.pb \
--output_node_names=toys --input_binary

python tools/optimize_for_inference.py \
--input=./export/frozen_network.pb \
--output=./export/optim_frozen_network.pb \
--input_names=./model/graph.pbtxt \
--output_names=toys \
--frozen_graph=True


## Utils

[Sipeed Maix Training Scripts](https://github.com/sipeed/maix_train)

https://github.com/tzutalin/ImageNet_Utils


python retrain.py --logtostderr --train_dir=./images/train --pipelin_config_path=./ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config





List of pretrained networks
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md


## Python 3 is the default version

> cd /usr/local/bin
> rm python
> ln -s python3 python
> rm pip
> ln -s pip3 pip

## Target Model for Talki

https://tfhub.dev/google/imagenet/mobilenet_v2_075_224/feature_vector/3
The module contains a trained instance of the network, packaged to get feature vectors from images.


MODEL_DIR=/Volumes/Projects/toynet/ python object_detection/export_tflite_ssd_graph.py --pipeline_config_path ${MODEL_DIR}ssdlite_mobilenet_v2_coco_toynet.config --trained_checkpoint_prefix ${MODEL_DIR}ssdlite_mobilenet_v2_coco_2018_05_09/model.ckpt.data-00000-of-00001 --output_directory ${MODEL_DIR}export2


cd research
export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim
PIPELINE_CONFIG_PATH=/Volumes/Projects/toynet/ssdlite_mobilenet_v2_coco_toynet.config
MODEL_DIR=/Volumes/Projects/toynet/
NUM_TRAIN_STEPS=50000
SAMPLE_1_OF_N_EVAL_EXAMPLES=1
python3 object_detection/model_main.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} --model_dir=${MODEL_DIR} \
    --num_train_steps=${NUM_TRAIN_STEPS} --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES --alsologtostderr
cd /Volume/Projects/toynet


### Object Detection Datasets

Working on [Jupyter notebooks on Colab](https://colab.research.google.com/drive/1TNj7az-RKI5V2CugP97Wj-fwT2GUruBs#scrollTo=u3sHchp8KeIt).

The [MCIndoor20000](https://www.sciencedirect.com/science/article/pii/S2352340917307424) is a fully-labeled image dataset that was launched in Marshfield Clinic to facilitate broad use of image classification and recognition. 

[YOLOv3-model-pruning](https://github.com/Lam1360/YOLOv3-model-pruning) what is pruning?


familynet. toys/hands/face


[shape-detection](https://github.com/jrieke/shape-detection)

[VOC2020 Pascal2](http://host.robots.ox.ac.uk:8080/pascal/VOC/voc2012/index.html#devkit)


## Defensive Datasets

Tabu

[texture-vs-shape](https://github.com/rgeirhos/texture-vs-shape)


## Guides for Setting up Data Science Environment

* [Mac ARM: Spinning up a Python Data Science Environment](https://github.com/mwidjaja1/DSOnMacARM)
* [aXeleRate](https://github.com/AIWintermuteAI/aXeleRate)
* [aXeleRate_pascal20_detector.ipynb example](https://colab.research.google.com/github/AIWintermuteAI/aXeleRate/blob/master/resources/aXeleRate_pascal20_detector.ipynb#scrollTo=hS9yMrWe02WQ)
* [experientials/K210_Yolo_framework](https://github.com/experientials/K210_Yolo_framework)
* [MobileNet v1 base 7 H5 demo](https://share.weiyun.com/5FgNE0b)
* [Kendryte K210 Animal Tracking](https://github.com/zyayoung/K210-Tracking)
* [Semantic Segmentation and Dataset iPython Notebook](https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_computer-vision/semantic-segmentation-and-dataset.ipynb#scrollTo=oykIVZNfkyxF)
* [Google Coral USB Accelerator](https://www.pyimagesearch.com/2019/05/13/object-detection-and-image-classification-with-google-coral-usb-accelerator/)


## ML Courses

* [Dive into Deep Learning](https://d2l.ai/index.html) [book](https://github.com/d2l-ai/d2l-book) [book en](https://github.com/d2l-ai/d2l-en)
* [D2L Attention](https://d2l.ai/chapter_attention-mechanisms/attention-cues.html)
* [d2l lib](https://github.com/d2l-ai/utils)
* [a-PyTorch-Tutorial-to-Object-Detection](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection)


## Improvements to be made

[Progress Bars](https://www.geeksforgeeks.org/progress-bars-in-python/)
[Customizing Training Loops in TensorFlow 2.0](https://wandb.ai/site/articles/wandb-customizing-training-loops-in-tensorflow-2)


